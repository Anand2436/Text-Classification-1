{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Name:  ['rec.sport.hockey', 'sci.space', 'soc.religion.christian', 'talk.politics.mideast', 'sci.electronics', 'comp.graphics', 'rec.autos', 'rec.sport.baseball', 'sci.med', 'sci.crypt', 'talk.religion.misc', 'misc.forsale', 'comp.sys.mac.hardware', 'talk.politics.misc', 'talk.politics.guns', 'comp.sys.ibm.pc.hardware', 'rec.motorcycles', 'comp.os.ms-windows.misc', 'comp.windows.x', 'alt.atheism']\n",
      "\n",
      "Total Documents:  20\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home/ash/MLCN/TextClassificationData/20_newsgroups/\"\n",
    "\n",
    "classes = os.listdir(base_dir)\n",
    "print(\"Classes Name: \",classes)\n",
    "print()\n",
    "print(\"Total Documents: \",len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Tf-Idf matrix for each class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_files(file):\n",
    "    text = file.read().lower() # read the file in lower cases\n",
    "    \n",
    "    text = re.sub('[^A-Za-z]', ' ', text) # remove non alphanumeric characters\n",
    "    \n",
    "    text = re.sub('\\s+', ' ', text) # Condense all white spaces\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download() # to download all packages of nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use small numbers for first time that is articles =  50, classes = 2 , features = 75 \n",
    "max_articles_of_each_class = 5\n",
    "no_of_classes = 2\n",
    "no_of_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf = {}\n",
    "idf = {}\n",
    "articles_added = {}\n",
    "selected_classes  = []\n",
    "\n",
    "for i in range(no_of_classes):\n",
    "    current_class = classes[i]\n",
    "    selected_classes.append(classes[i])\n",
    "    \n",
    "    articles_added[current_class] = []\n",
    "    class_dir = base_dir + current_class # base_dir already contains '/' atlast therefore not added\n",
    "    \n",
    "    #print(class_dir)\n",
    "    \n",
    "    all_articles = os.listdir(class_dir)\n",
    "    \n",
    "    for j in range(max_articles_of_each_class):\n",
    "        current_file = class_dir + '/' + all_articles[j] # class_dir doesnot contain '/, atlast\n",
    "        \n",
    "        #print(current_file)\n",
    "        articles_added[current_class].append(all_articles[j])\n",
    "        \n",
    "        file= open(current_file, encoding = \"ISO-8859-1\")\n",
    "        text = preprocess_files(file)\n",
    "        file.close()\n",
    "        text_words = text.split()\n",
    "        \n",
    "        # update tf dictionary\n",
    "        word_count = Counter(text_words)\n",
    "        \n",
    "        for word,freq in word_count.items(): # items syntax stored as ele,fre Thats why word ,freq both mentioned\n",
    "            if (word in tf):\n",
    "                tf[word] += freq\n",
    "            else :\n",
    "                tf[word] = freq\n",
    "        \n",
    "        \n",
    "        # updating idf\n",
    "        word_set = set(text_words)\n",
    "        \n",
    "        for word in word_set:\n",
    "            if word in idf:\n",
    "                idf[word] += 1\n",
    "            else :\n",
    "                idf[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['newsgroups', 'rec', 'sport', 'hockey', 'path', 'cantaloupe', 'srv', 'cs', 'cmu', 'edu', 'crabapple', 'fs', 'ece', 'europa', 'eng', 'gtefsd', 'com', 'howland', 'reston', 'ans', 'net', 'wupost', 'eclnews', 'cec', 'jca', 'from', 'wustl', 'joseph', 'charles', 'achkar', 'subject', 'grant', 'fuhr', 'leads', 'sabres', 'message', 'id', 'apr', 'wuecl', 'sender', 'usenet', 'news', 'administrator', 'nntp', 'posting', 'host', 'organization', 'washington', 'university', 'st', 'louis', 'mo', 'date', 'wed', 'gmt', 'lines', 'buffalo', 'is', 'up', 'the', 'series', 'with', 'boston', 'and', 'reason', 'playoff', 'hungry', 'he', 's', 'proving', 'once', 'again', 'why', 'they', 'call', 'him', 'money', 'goaltender', 'might', 'not', 'be', 'one', 'of', 'best', 'goaltenders', 'in', 'league', 'anymore', 'statistically', 'at', 'least', 'but', 'that', 'can', 'make', 'big', 'save', 'right', 'time', 'leafs', 'should', 'have', 'kept', 'probably', 'would', 'had', 'a', 'chance', 'against', 'powerhouse', 'detroit', 'where', 'was', 'andreychoke', 'game', 'i', 'see', 'huge', 'smile', 'on', 'gerald', 'face', 'after', 'performance', 'l', 'e', 'z', 'b', 'u', 'joe', 'ashkar', 'contact', 'for', 'blues', 'saint', 'das', 'harvard', 'noc', 'near', 'uunet', 'ulowell', 'woods', 'mosscropm', 'bleep', 'bruins', 'lose', 'o', 't', 'manager', 'massachusetts', 'lowell', 'fri', 'lost', 'stand', 'it', 'aside', 'frustrated', 'ravings', 'must', 'give', 'credit', 'are', 'making', 'good', 'most', 'their', 'scoring', 'opportunities', 'playing', 'great', 'defense', 'players', 'seem', 'to', 'get', 'control', 'puck', 'anywhere', 'except', 'rare', 'occasions', 'also', 'doing', 'an', 'excellent', 'job', 'clearing', 'away', 'rebounds', 'when', 'needed', 'getting', 'plenty', 'help', 'has', 'been', 'rather', 'well', 'better', 'than', 'indicated', 'by', 'score', 'lacking', 'extra', 'drive', 'earlier', 'part', 'as', 'result', 'keeps', 'leaving', 'ice', 'end', 'period', 'goals', 'down', 'this', 'stop', 'if', 'any', 'hope', 'winning', 'single', 'outlook', 'bruin', 'advancement', 'second', 'round', 'quite', 'bleak', 'imho', 'need', 'first', 'do', 'since', 'outplayed', 'nd', 'rd', 'periods', 'scary', 'thing', 'll', 'going', 'grad', 'school', 'next', 'year', 'never', 'cheer', 'you', 'convert', 'me', 'mtm', 'mike', 'mosscrop', 'die', 'hard', 'fan', 'dept', 'chemistry', 'umass', 'magnesium', 'club', 'cc', 'sei', 'cis', 'ohio', 'state', 'pacific', 'mps', 'zaphod', 'sol', 'ctr', 'columbia', 'destroyer', 'ubc', 'ca', 'utcsri', 'newsflash', 'concordia', 'mizar', 'umanitoba', 'umward', 'derek', 'ward', 're', 'winnipeg', 'vs', 'vancouver', 'c', 'yf', 'imy', 'ccu', 'manitoba', 'canada', 'x', 'newsreader', 'tin', 'pl', 'references', 'rhancinno', 'iskut', 'ucs', 'mon', 'david', 'downie', 'dave', 'commerce', 'wrote', 'speaking', 'paddock', 'what', 'slagging', 'sandlak', 'puts', 'his', 'mind', 'physical', 'presence', 'waking', 'real', 'mistake', 'isn', 'sandbag', 'out', 'injury', 'now', 'anyways', 'perhaps', 'meant', 'say', 'momesso', 'cheap', 'short', 'artist', 'all', 'more', 'sense', 'wpg', 'computer', 'science', 'ogicse', 'decwrl', 'sun', 'barr', 'ebay', 'jethro', 'corp', 'rambler', 'jake', 'jason', 'cockroft', 'blood', 'tee', 'shirts', 'pqkfp', 'd', 'article', 'pfnm', 'msuinfo', 'cl', 'msu', 'reply', 'distribution', 'world', 'microsystems', 'inc', 'believe', 'or', 'bob', 'probert', 'line', 'clothes', 'whole', 'shirt', 'says', 'fight', 'probie', 'cool', 'sound', 'like', 'cult', 'classic', 'someone', 'post', 'address', 'phone', 'store', 'sells', 'these', 'thanks', 'bb', 'andrew', 'usc', 'utexas', 'walter', 'porthos', 'mse', 'bellcore', 'michael', 'evenchick', 'f', 'livingston', 'nj', 'followup', 'r', 'p', 'bigboote', 'wpi', 'netnews', 'system', 'software', 'ching', 'bigwpi', 'logistician', 'writes', 'am', 'wearing', 'nhl', 'know', 'only', 'ray', 'borque', 'greatly', 'appreciated', 'thanx', 'reigns', 'supreme', 'go', 'blue', 'tigers', 'pistons', 'lions', 'red', 'wings', 'pierre', 'turgeon', 'islanders', 'xref', 'sci', 'space', 'answers', 'concert', 'borg', 'unc', 'mail', 'leech', 'jon', 'faq', 'interest', 'groups', 'publications', 'keywords', 'frequently', 'asked', 'questions', 'expires', 'may', 'diffs', 'poster', 'north', 'carolina', 'chapel', 'hill', 'approved', 'request', 'mit', 'supersedes', 'mahler', 'archive', 'name', 'last', 'modified', 'activist', 'research', 'aia', 'aerospace', 'industry', 'association', 'professional', 'group', 'primary', 'membership', 'major', 'firms', 'headquartered', 'dc', 'area', 'acts', 'voice', 'opinions', 'usually', 'backed', 'reams', 'analyses', 'reputations', 'aiaa', 'american', 'institute', 'aeronautics', 'astronautics', 'somewhere', 'about', 'members', 'local', 'chapters', 'around', 'country', 'largest', 'la', 'san', 'francisco', 'seattle', 'nw', 'houston', 'orange', 'county', 'plus', 'student', 'union', 'represent', 'aviation', 'professionals', 'engineers', 'managers', 'financial', 'types', 'nationwide', 'holds', 'over', 'conferences', 'topics', 'publishes', 'technical', 'journals', 'journal', 'spacecraft', 'rockets', 'etc', 'reference', 'books', 'source', 'current', 'art', 'through', 'published', 'papers', 'proceedings', 'offers', 'continuing', 'education', 'classes', 'design', 'committees', 'standards', 'society', 'centralized', 'resume', 'jobs', 'function', 'provides', 'search', 'low', 'cost', 'health', 'life', 'insurance', 'lobbies', 'appropriate', 'legislation', 'organizations', 'pushing', 'iras', 'individual', 'retirement', 'accounts', 'very', 'active', 'public', 'policy', 'arm', 'works', 'directly', 'media', 'congress', 'government', 'agencies', 'legislative', 'liaison', 'clearinghouse', 'inquiries', 'technology', 'issues', 'reasonably', 'non', 'partisan', 'company', 'viewpoint', 'yr', 'memberships', 'less', 'center', 'enfant', 'promenade', 'sw', 'amsat', 'develops', 'small', 'satellites', 'variety', 'uses', 'amateur', 'radio', 'enthusiasts', 'various', 'supplies', 'quicktrak', 'satellite', 'tracking', 'pc', 'mac', 'amiga', 'corporation', 'box', 'asera', 'australian', 'engineering', 'profit', 'organisation', 'coordinate', 'promote', 'conduct', 'projects', 'australia', 'involving', 'both', 'international', 'primarily', 'collaborators', 'activities', 'include', 'development', 'sounding', 'especially', 'microsatellites', 'high', 'altitude', 'balloons', 'payloads', 'levels', 'open', 'person', 'interested', 'participating', 'monthly', 'newsletter', 'quarterly', 'dual', 'subscription', 'subscriptions', 'ltd', 'po', 'ryde', 'nsw', 'email', 'lindley', 'syd', 'dit', 'csiro', 'au', 'bis', 'british', 'interplanetary', 'oldest', 'pro', 'two', 'spaceflight', 'covering', 'containing', 'term', 'probes', 'interstellar', 'missions', 'study', 'probe', 'called', 'daedalus', 'south', 'lambeth', 'road', 'london', 'sz', 'england', 'no', 'dues', 'information', 'available', 'present', 'isu', 'graduate', 'level', 'educational', 'institution', 'dedicated', 'promoting', 'peaceful', 'exploration', 'multi', 'cultural', 'disciplinary', 'further', 'summer', 'session', 'program', 'permanent', 'campus', 'please', 'send', 'messages', 'isunet', 'executive', 'offices', 'avenue', 'th', 'floor', 'cambridge', 'ma', 'fax', 'defunct', 'founded', 'keith', 'carolyn', 'henson', 'advocate', 'colonization', 'its', 'success', 'preventing', 'us', 'participation', 'un', 'moon', 'treaty', 'late', 'merged', 'national', 'forming', 'nsc', 'general', 'known', 'comprised', 'conduit', 'social', 'gathering', 'chapter', 'meetings', 'invited', 'speakers', 'who', 'heavy', 'hitters', 'field', 'annual', 'conference', 'definitive', 'data', 'planning', 'programs', 'approx', 'nss', 'distinguished', 'network', 'supports', 'agenda', 'man', 'including', 'nasa', 'station', 'ad', 'astra', 'glossy', 'magazine', 'runs', 'shuttle', 'launch', 'tours', 'hotline', 'telephone', 'services', 'sponsor', 'associated', 'spacecause', 'spacepac', 'political', 'lobbying', 'youth', 'senior', 'regular', 'department', 'pennsylvania', 'planetary', 'carl', 'sagan', 'advocacy', 'report', 'supported', 'seti', 'hardware', 'financially', 'support', 'recently', 'amended', 'manned', 'mission', 'mars', 'catalina', 'pasadena', 'ssi', 'studies', 'dr', 'gerard', 'neill', 'physicist', 'freeman', 'dyson', 'took', 'presidency', 'death', 'update', 'bimonthly', 'describing', 'work', 'progress', 'conducts', 'mass', 'drivers', 'lunar', 'mining', 'processes', 'simulants', 'composites', 'materials', 'solar', 'power', 'biennial', 'princeton', 'manufacturing', 'associates', 'fund', 'rosedale', 'seds', 'students', 'based', 'schools', 'universities', 'entirely', 'run', 'each', 'independent', 'coordinates', 'own', 'nationally', 'scholarship', 'competition', 'contests', 'meeting', 'room', 'w', 'odyssey', 'athena', 'determined', 'family', 'bi', 'receive', 'discount', 'handbook', 'leaders', 'interacting', 'staff', 'operates', 'process', 'office', 'west', 'coast', 'ave', 'se', 'ocean', 'park', 'blvd', 'suite', 'santa', 'monica', 'action', 'committee', 'researches', 'policies', 'candidates', 'updates', 'price', 'while', 'does', 'regional', 'contacts', 'activity', 'election', 'contributing', 'volunteers', 'united', 'states', 'foundation', 'member', 'donations', 'understanding', 'hosts', 'teachers', 'others', 'other', 'developing', 'lesson', 'plans', 'use', 'teach', 'basic', 'skills', 'such', 'reading', 'spacewatch', 'ussf', 'events', 'charter', 'teacher', 'college', 'hs', 'jr', 'elementary', 'founder', 'colorado', 'springs', 'co', 'designing', 'building', 'sail', 'longer', 'similar', 'many', 'jpl', 'employees', 'lend', 'talents', 'project', 'wsf', 'partial', 'funding', 'palomar', 'sky', 'survey', 'extremely', 'successful', 'earth', 'asteroids', 'notebook', 'page', 'associate', 'minimum', 'always', 'welcome', 'y', 'california', 'daily', 'mcgraw', 'coverage', 'air', 'smithsonian', 'boulder', 'esa', 'european', 'agency', 'periodicals', 'generally', 'free', 'charge', 'document', 'them', 'detail', 'ames', 'pub', 'esapublications', 'final', 'frontier', 'market', 'history', 'book', 'reviews', 'articles', 'g', 'wonders', 'everything', 'wanted', 'military', 'publishing', 'mt', 'morris', 'il', 'elsewhere', 'weekly', 'covers', 'civil', 'said', 'business', 'spotty', 'springfield', 'va', 'discounts', 'astronautical', 'sciences', 'times', 'details', 'aas', 'rolling', 'mill', 'place', 'gps', 'semi', 'reports', 'new', 'analysis', 'affecting', 'product', 'shaping', 'applications', 'willamette', 'eugene', 'qualified', 'individuals', 'write', 'sample', 'copy', 'innovation', 'advanced', 'concepts', 'revised', 'version', 'commercial', 'encounter', 'depth', 'diagrams', 'lists', 'experiments', 'interviews', 'people', 'involved', 'mostly', 'payload', 'manifests', 'schedules', 'assessment', 'every', 'sewell', 'trade', 'calendar', 'paragraph', 'notes', 'online', 'fee', 'unknown', 'investor', 'irregular', 'internet', 'column', 'aspects', 'limited', 'paper', 'edition', 'seal', 'beach', 'following', 'phillips', 'montrose', 'potomac', 'mc', 'overview', 'undocumented', 'anyone', 'care', 'descriptions', 'mentioned', 'inclusion', 'answer', 'encouraged', 'so', 'above', 'how', 'become', 'astronaut', 'astro', 'darwin', 'sura', 'gatech', 'astronomical', 'mnemonics', 'section', 'posted', 'gathered', 'flurries', 'mnemonic', 'postings', 'spectral', 'classification', 'sequence', 'k', 'm', 'n', 'oh', 'fine', 'girl', 'kiss', 'sweetheart', 'dell', 'fiasco', 'gonna', 'kill', 'surely', 'obese', 'balding', 'astronomy', 'found', 'guilty', 'killed', 'reluctant', 'nonscience', 'octopus', 'brains', 'favorite', 'gastronomical', 'kitchen', 'menu', 'requires', 'sauce', 'odd', 'ball', 'astronomers', 'find', 'kooky', 'really', 'nifty', 'stuff', 'ferocious', 'gorilla', 'my', 'roomate', 'saturday', 'boy', 'flash', 'godzilla', 'kills', 'mothra', 'surprising', 'grade', 'bad', 'afternoons', 'fermented', 'grapes', 'keep', 'mrs', 'richard', 'nixon', 'smiling', 'backward', 'astronomer', 'forget', 'geocentricity', 'kepler', 'motions', 'reveal', 'nature', 'simplicity', 'our', 'faculty', 'gets', 'monday', 'oven', 'baked', 'ants', 'fried', 'gently', 'moist', 'retain', 'natural', 'succulence', 'overseas', 'broadcast', 'rodan', 'named', 'successor', 'overweight', 'boys', 'fat', 'girls', 'munching', 'bored', 'gratification', 'knowing', 'bloody', 'grades', 'order', 'planets', 'mercury', 'venus', 'terra', 'jupiter', 'saturn', 'uranus', 'neptune', 'pluto', 'earnest', 'mother', 'just', 'served', 'nine', 'pizzas', 'thoughtfully', 'made', 'jelly', 'sandwich', 'under', 'protest', 'erotic', 'mate', 'joyfully', 'satisfies', 'unusual', 'needs', 'passionately', 'men', 'easily', 'jugs', 'serve', 'useful', 'nocturnal', 'purposes', 'early', 'jug', 'noble', 'educated', 'showed', 'eager', 'exhausted', 'swept', 'nebula', 'voters', 'earn', 'showing', 'polls', 'pizza', 'pies', 'viscious', 'elephants', 'john', 'suzy', 'uncle', 'protection', 'makes', 'undergo', 'numerous', 'perturbations', 'mein', 'vater', 'erklaert', 'mir', 'jeden', 'sonntag', 'unsere', 'niedlichen', 'planeten', 'father', 'explains', 'sunday', 'verachte', 'einen', 'menschen', 'seinem', 'unglueck', 'nie', 'punkt', 'scorn', 'despise', 'misfortune', 'luck', 'misery', 'colors', 'spectrum', 'yellow', 'green', 'indigo', 'violet', 'roy', 'biv', 'pronounce', 'york', 'gave', 'battle', 'vain', 'read', 'your', 'verse', 'galilean', 'io', 'ganymede', 'callisto', 'expect', 'god', 'cries', 'eat', 'cheese', 'embarrass', 'christians', 'ich', 'erschrecke', 'guten', 'christen', 'scare', 'saturnian', 'met', 'thip', 'miriam', 'enchiladas', 'taste', 'divine', 'tell', 'her', 'proud', 'mimas', 'enceladus', 'tethys', 'dione', 'rhea', 'titan', 'hyperion', 'iapetus', 'phoebe', 'uranian', 'mauto', 'mispronunciations', 'afflict', 'too', 'often', 'angel', 'uriel', 'takes', 'opium', 'miranda', 'ariel', 'umbriel', 'titania', 'oberon', 'note', 'remaining', 'sections', 'appear', 'cover', 'material', 'relevance', 'contacting', 'companies', 'misc', 'math', 'rochester', 'udel', 'ub', 'dsinc', 'upenn', 'drexel', 'coe', 'jpw', 'cbis', 'wetstein', 'sunrise', 'sunset', 'philadelphia', 'pa', 'hello', 'looking', 'algorithm', 'used', 'compute', 'appreciate', 'advice', 'purdue', 'yuma', 'wallacen', 'colostate', 'nathan', 'wallace', 'orion', 'acns', 'account', 'sat', 'beethoven', 'readers', 'starflight', 'mallove', 'gregory', 'matloff', 'isbn', 'relevant', 'nuclear', 'pulse', 'propulsion', 'contains', 'lots', 'academically', 'inclined', 'enjoy', 'reality', 'ancient', 'alphaean', 'proverb', 'digex', 'prb', 'access', 'pat', 'express', 'communications', 'usa', 'rebsk', 'khc', 'permanet', 'org', 'qjs', 'j', 'mksol', 'dseg', 'ti', 'mccall', 'fred', 'either', 'actually', 'elvis', 'maybe', 'lemur', 'sometimes', 'difficulty', 'telling', 'which', 'definitely', 'couldn', 'spell', 'listen', 'songs'])\n"
     ]
    }
   ],
   "source": [
    "# updating tf_idf matrix\n",
    "\n",
    "tf_idf = {}\n",
    "for key in tf.keys():\n",
    "    tf_idf[key] = tf[key]/idf[key]\n",
    "    \n",
    "print(type(tf_idf))\n",
    "print(tf_idf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"] 179\n"
     ]
    }
   ],
   "source": [
    "# StopWords\n",
    "\n",
    "st = stopwords.words(\"english\")\n",
    "print(st,len(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove StopWords from our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450\n",
      "True\n",
      "False\n",
      "1351\n"
     ]
    }
   ],
   "source": [
    "print(len(tf_idf))\n",
    "\n",
    "print('he' in tf_idf.keys())\n",
    "\n",
    "for stop_word in stopwords.words(\"english\"):\n",
    "    if (stop_word in tf_idf.keys()):\n",
    "        tf_idf.pop(stop_word)\n",
    "        \n",
    "print('he' in tf_idf.keys())\n",
    "print(len(tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting k features having max tf-idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tf_idf))\n",
    "tf_idf = sorted(tf_idf.items(),key = operator.itemgetter(1))\n",
    "tf_idf.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select k features\n",
    "features = set()\n",
    "count = {}\n",
    "for i in range(no_of_features):\n",
    "    features.add(tf_idf[i][0])\n",
    "    count[tf_idf[i][0]] = tf_idf[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edu', 'society', 'membership', 'groups', 'space', 'publishes', 'c', 'aerospace', 'year', 'box'}\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edu 8.6\n",
      "society 11.0\n",
      "membership 10.0\n",
      "groups 10.0\n",
      "space 17.2\n",
      "publishes 10.0\n",
      "c 30.0\n",
      "aerospace 13.0\n",
      "year 10.0\n",
      "box 10.0\n"
     ]
    }
   ],
   "source": [
    "# printing features with their tf-idf values\n",
    "\n",
    "for word in features:\n",
    "    print(word, count[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have got our features , we have to run through these features with whole data available (training and testing) \n",
    "\n",
    "\n",
    "To convert the files into a matrix format like the below one f: features , d: documents\n",
    "\n",
    "        f1 f2 f3 f4 ...\n",
    "     d1  1  1   2  3\n",
    "     d2  3  3   4  3\n",
    "     d3  1  2   3  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
